<!DOCTYPE html>
<html lang="en-us">

  <head>
  
<meta http-equiv="X-UA-Compatible" content="IE=edge" /> 
<meta http-equiv="content-type" content="text/html; charset=utf-8" /> 

  <!-- Enable responsiveness on mobile devices-->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" /> 

  <title>
    
      Scrapy学习:官方例子 &middot; DoSun's Blog
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="https://use.fontawesome.com/a8343af6c0.css">
  <script type="text/javascript" src="/assets/js/jquery-3.2.1.min.js"></script>
  <link rel="shortcut icon" href="/assets/images/icon.ico">

  <!-- RSS -->
  

  
</head>


  <body class="posts">

    <div id="sidebar">
    <div id='cover-author-image' align='center'>
      <img src="http://ows0v592v.bkt.clouddn.com/DoSun.jpg" alt="DoSun">
    </div>
    <header>
      <div class="site-title" align='center'>
        <a href="/">
          DoSun's Blog
        </a>
      </div>
      <p class="lead">没事写写东西,记点笔记</p>
    </header>
    <nav id="sidebar-nav-links">
    
      <a class="home-link "
          href="/">Home</a>
    
    
  
    
  
    
    


  
    
  

  
    
      <a class="category-link "
          href="/category/DB.html">Database</a>
    
  

  
    
      <a class="category-link "
          href="/category/Django.html">Django</a>
    
  

  
    
      <a class="category-link "
          href="/category/HTTP.html">HTTP</a>
    
  

  
    
      <a class="category-link "
          href="/category/Scrapy.html">Scrapy</a>
    
  

  
    
  

  
    
  </nav>
  

    <nav id="sidebar-icon-links">
    <a id="github-link"
       class="icon" title="Github Profile" aria-label="Github Profile"
       href="https://github.com/XDfield">
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path d="M256,0C114.615,0,0,114.615,0,256s114.615,256,256,256s256-114.615,256-256S397.385,0,256,0z M408.028,408.028
	c-19.76,19.758-42.756,35.266-68.354,46.093c-6.503,2.75-13.106,5.164-19.8,7.246V423c0-20.167-6.917-35-20.75-44.5
	c8.667-0.833,16.625-2,23.875-3.5s14.917-3.667,23-6.5s15.333-6.208,21.75-10.125s12.583-9,18.5-15.25s10.875-13.333,14.875-21.25
	s7.167-17.417,9.5-28.5s3.5-23.292,3.5-36.625c0-25.833-8.417-47.833-25.25-66c7.667-20,6.833-41.75-2.5-65.25l-6.25-0.75
	c-4.333-0.5-12.125,1.333-23.375,5.5s-23.875,11-37.875,20.5c-19.833-5.5-40.417-8.25-61.75-8.25c-21.5,0-42,2.75-61.5,8.25
	c-8.833-6-17.208-10.958-25.125-14.875s-14.25-6.583-19-8s-9.167-2.292-13.25-2.625s-6.708-0.417-7.875-0.25s-2,0.333-2.5,0.5
	c-9.333,23.667-10.167,45.417-2.5,65.25c-16.833,18.167-25.25,40.167-25.25,66c0,13.333,1.167,25.542,3.5,36.625
	s5.5,20.583,9.5,28.5s8.958,15,14.875,21.25s12.083,11.333,18.5,15.25s13.667,7.292,21.75,10.125s15.75,5,23,6.5
	s15.208,2.667,23.875,3.5c-13.667,9.333-20.5,24.167-20.5,44.5v39.115c-7.549-2.247-14.99-4.902-22.3-7.994
	c-25.597-10.827-48.594-26.335-68.353-46.093c-19.758-19.759-35.267-42.757-46.093-68.354C46.679,313.195,41,285.043,41,256
	s5.679-57.195,16.879-83.675c10.827-25.597,26.335-48.594,46.093-68.353c19.758-19.759,42.756-35.267,68.353-46.093
	C198.805,46.679,226.957,41,256,41s57.195,5.679,83.675,16.879c25.599,10.827,48.595,26.335,68.354,46.093
	c19.758,19.758,35.266,42.756,46.093,68.353C465.321,198.805,471,226.957,471,256s-5.679,57.195-16.879,83.675
	C443.294,365.271,427.786,388.27,408.028,408.028z"/>
</svg>
    </a>

    <a href="mailto:chenxuan958864951@qq.com"
       class="icon" title="Email" aria-label="Email" id="email">
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path d="M256,0C114.615,0,0,114.615,0,256s114.615,256,256,256s256-114.615,256-256S397.385,0,256,0z M128,128h256
	c4.569,0,9.002,0.981,13.072,2.831L256,295.415L114.928,130.83C118.998,128.982,123.431,128,128,128z M96,352V160
	c0-0.67,0.028-1.336,0.07-2l93.832,109.471L97.103,360.27C96.381,357.602,96,354.827,96,352z M384,384H128
	c-2.827,0-5.601-0.381-8.27-1.104l91.059-91.06L256,344.586l45.212-52.747l91.058,91.06C389.6,383.619,386.827,384,384,384z
	 M416,352c0,2.827-0.381,5.6-1.103,8.27l-92.801-92.799L415.93,158c0.042,0.664,0.07,1.33,0.07,2V352z"/>
</svg>
    </a>

    <a href="http://steamcommunity.com/id/XDfield/"
       class="icon" title="Steam Profile" aria-label="Steam Profile" id="steam">
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path d="M151.961,418.005c13.572,0,26.893-6.567,34.986-18.708c12.867-19.301,7.651-45.377-11.649-58.244l-33.037-22.023
	c5.654-1.54,11.597-2.379,17.739-2.379c37.196,0,67.348,30.152,67.348,67.35s-30.153,67.349-67.349,67.349
	c-36.202,0-65.722-28.565-67.274-64.387l35.977,23.984C135.863,415.72,143.955,418.005,151.961,418.005z M426.67,0
	C473.608,0,512,38.406,512,85.344v341.314C512,473.626,473.608,512,426.67,512H85.344C38.406,512,0,473.625,0,426.659V325.145
	l60.667,40.444c-5.826,31.587,3.469,65.415,27.899,89.845c39.452,39.452,103.415,39.452,142.868,0
	c24.234-24.232,33.575-57.715,28.039-89.082l124.528-111.494L384,254.857c23.124-3.319,45.408-13.872,63.197-31.661
	c43.737-43.738,43.737-114.653,0-158.392c-43.74-43.739-114.654-43.739-158.393,0c-17.789,17.789-28.343,40.073-31.662,63.196l0,0
	L154.796,283.115c-15.924,0.816-31.689,5.382-45.863,13.695L0,224.189V85.344C0,38.406,38.405,0,85.343,0H426.67z M448,144
	c0-44.183-35.817-80-80-80s-80,35.817-80,80s35.817,80,80,80S448,188.183,448,144z M320,144c0-26.51,21.49-48,48-48s48,21.49,48,48
	s-21.49,48-48,48S320,170.51,320,144z"/>
</svg>
    </a>
  
  
</nav>
    <p align='center' style="font-size: 14px">
      2017-09-26 &copy; DoSun.
      <a href="/LICENSE.md">MIT License</a>
    </p>
</div>

    <main class="container">
      
      <div class="content">
  <header>
    <h1 class="post-title">Scrapy学习:官方例子</h1>
  </header>
  <div class="post-meta">
  <span class="post-date">26 Sep 2017</span>
  <span class="post-categories">
    
      &bull;

      
      
      

      
        <a href="/category/Scrapy.html">
          Scrapy
        </a>
      
    
  </span>
</div>

  <div class="post-body">
    <p><a href="https://scrapy.org/">Scrapy</a>是一个强大的爬虫框架,现在开始来学习.</p>

<hr />
<h2 id="安装">安装</h2>
<p>scrapy支持python2.7和python3.3+<br />
跟普通的python库安装一样,可以直接在命令行输入: <code class="highlighter-rouge">pip install scrapy</code><br />
在windows下,如果有安装Anaconda或者Miniconda的,也可以输入: <code class="highlighter-rouge">conda install -c conda-forge scrapy</code></p>

<hr />
<h2 id="官方例子">官方例子</h2>
<p>这里是<a href="https://doc.scrapy.org/en/latest/">官方文档</a>提供的一个学习例子,学习使用下.</p>
<h3 id="目的">目的</h3>
<p>爬取 <em>quotes.toscrape.com</em> 上的信息,该网站主要显示了一些知名作者写的话.<br />
该教程将会按一下顺序来完成:</p>
<ol>
  <li>创建一个新的Scrapy项目</li>
  <li>写一个spider来爬取一个站点并提取数据</li>
  <li>使用命令行来导出爬取到的数据</li>
  <li>调整spider来让它能够沿着页面顺序爬取</li>
  <li>使用spider的参数</li>
</ol>

<hr />
<h3 id="创建项目">创建项目</h3>
<p>在开始写爬取数据前,先创建一个Scrapy项目.在命令行输入: <code class="highlighter-rouge">scrapy startproject projectname</code><br />
该命令会创建一个名为’projectname’的文件夹,该文件夹的结构如下:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>projectname/
    scrapy.cfg  # 配置文件 
    projectname/  # 一个python包,你的代码应从这里导入
        __init__.py
        iterms.py  # 项目中对'物件'的定义
        pipelines.py  # 项目的pipelines
        setting.py  # 项目的设置
        spiders/  # 待会你的spider存放的位置
            __init__.py
</code></pre>
</div>

<h3 id="来写第一个spider">来写第一个Spider</h3>
<p>Spider是我们来定义的一个类,Scrapy将会调用它来从网站上(或者是一堆网站上)抓取信息.该类必须是<code class="highlighter-rouge">scrapy.Spider</code>的子类,并且要定义最初的请求目标,至于定义如何按顺序爬取还有解析规则都是可选的.<br />
现在在projectname/spders文件夹里创建一个名为quotes_spider.py的文件,这将存放我们的第一个Spider的代码,内容如下:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'quotes'</span>
    
    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
            <span class="s">'http://quotes.toscrape.com/page/2/'</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s">'quotes-</span><span class="si">%</span><span class="s">s.html'</span> <span class="o">%</span> <span class="n">page</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">'Save file </span><span class="si">%</span><span class="s">s'</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
</code></pre>
</div>
<p>正如你所看到的,我们的Spider继承于<code class="highlighter-rouge">scrapy.Spider</code>,并且定义了一些属性与方法:</p>
<ul>
  <li>name: Spider的标识符.它在一个项目中应该是唯一的,也就是说对于两个不同的Spider不能有同样的name.</li>
  <li>start_requests(): 必须返回一个可迭代的Requests(可以是返回一个’请求’的列表或者一个生成器),用于让Spider开始爬取.随后,接下来要的请求会从这些初始的请求中连续生成.</li>
  <li>parse(): 在每一个请求得到响应后,将会调用该方法来进行处理.它会接收一个TextResponse的实例为参数,该实例包含了响应页面的主体.
    <blockquote>
      <p>parse()方法通常会用来解析响应页面,提取需要爬取的信息,还有寻找接下来要爬取的链接并为他们创建新的请求.</p>
    </blockquote>
  </li>
</ul>

<h3 id="运行spider">运行Spider</h3>
<p>要让spider开始工作,只需回到我们的项目目录,并在命令行输入: <code class="highlighter-rouge">scrapy crawl quotes</code><br />
该命令会运行我们刚才创建的名为<code class="highlighter-rouge">quotes</code>的spider,它会发送一个域名为’quotes.toscrape.com’的请求,在命令行内可以看到相应的输出信息.<br />
运行完后,检查当前目录下,会生成两个新的文件:’quotes-1.html’和’quotes-2.html’,其内容为各个请求的响应,正如我们的<code class="highlighter-rouge">parse()</code>方法所写的.</p>
<blockquote>
  <p>现在还未开始解析得到的html页面,稍后会进行这方面的操作.</p>
</blockquote>

<h3 id="爬取过程的大致流程">爬取过程的大致流程</h3>
<p>Scrapy处理了我们的Spider中的<code class="highlighter-rouge">start_requests</code>方法所返回的<code class="highlighter-rouge">scrapy.Request</code>对象.在接收到响应后,实例化一个<code class="highlighter-rouge">Response</code>对象,然后调用与请求相关联的回调函数(在这个例子中,就是<code class="highlighter-rouge">parse</code>方法),将响应传递过去.</p>

<h3 id="关于start_requests方法的简化">关于start_requests方法的简化</h3>
<p>我们可以定义一个带有一系列url值,名为<code class="highlighter-rouge">start_urls</code>的列表作为类属性,而不用实现一个<code class="highlighter-rouge">start_requests</code>方法来生成各个url的<code class="highlighter-rouge">scrapy.Request</code>对象.这个列表中的值将会被默认的<code class="highlighter-rouge">start_requests</code>方法使用并在你的spider中创建初始请求:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'quotes'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
        <span class="s">'http://quotes.toscrape.com/page/2/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c"># balabalaba...</span>
</code></pre>
</div>
<p>至于<code class="highlighter-rouge">parse()</code>方法,即使我们没有自己将它注册为各个请求的回调函数,Scrapy还是会自己调用它来处理请求,因为Scrapy默认的就是调用名为<code class="highlighter-rouge">parse()</code>的方法.</p>

<h3 id="提取数据">提取数据</h3>
<p>先在Scrapy的终端界面测试下选择器的使用.命令行输入: <code class="highlighter-rouge">scarpy shell 'http://quotes.toscrape.com/page/1/'</code></p>
<blockquote>
  <p><strong>注意:</strong> 在输入url的时候最后要记得闭合(带上’/’),否则会有各种问题.<br />
在Windows上,使用双引号: <code class="highlighter-rouge">scrapy shell "http://quotes.toscrape.com/page/1/"</code></p>
</blockquote>

<p>接着在终端可以看到一些响应的输出.接下来可以使用CSS来对<code class="highlighter-rouge">response</code>对象进行元素选择:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title'</span><span class="p">)</span>
<span class="p">[</span><span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">'descendant-or-self::title'</span><span class="n">data</span><span class="o">=</span><span class="s">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span><span class="o">&gt;</span><span class="p">]</span>
</code></pre>
</div>
<p>运行<code class="highlighter-rouge">response.css('title')</code>的结果会返回一个列表类型的对象<code class="highlighter-rouge">SelectorList</code>,它呈现了包含着XML/HTML元素的一些<code class="highlighter-rouge">Selector</code>对象,可以对它进行进一步的选择提取.<br />
要提取标题内部的文字,可以这么做:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="p">[</span><span class="s">'Quotes to Scrape'</span><span class="p">]</span>
</code></pre>
</div>
<p>有两点需要注意:</p>
<ol>
  <li>在css的提取中添加了’::text’,这意味着只提取&lt;title&gt;元素内部的文字.如果不加的话会返回整个元素,包括它的标签:
    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="p">[</span><span class="s">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span><span class="p">]</span>
</code></pre>
    </div>
  </li>
  <li>调用<code class="highlighter-rouge">extract()</code>会返回一个列表,因为处理的是一个<code class="highlighter-rouge">SelectorList</code>对象.如果只想要提取第一个结果,在该例子中,可以直接使用:
    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="s">'Quotes to Scrape'</span>
</code></pre>
    </div>
    <p>或者是:</p>
    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title::text'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="s">'Quotes to Scrape'</span>
</code></pre>
    </div>
    <blockquote>
      <p>不过还是推荐使用<code class="highlighter-rouge">extract_first()</code>方法,可以避免发生<code class="highlighter-rouge">IndexError</code>错误,即使是在未找到匹配的元素的情况下,也会返回None.</p>
    </blockquote>
  </li>
</ol>

<p>对大多数爬取代码来说,若在页面上未发现要找的信息我们就需要对这些错误更加包容,即使是爬取失败,我们也至少得到一些信息.<br />
除了使用<code class="highlighter-rouge">extract()</code>和<code class="highlighter-rouge">extract_first()</code>方法,还可以使用<code class="highlighter-rouge">re()</code>方法来通过正则表达式进行提取:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r'Quotes.*'</span><span class="p">)</span>
<span class="p">[</span><span class="s">'Quotes to Scrape'</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r'Q</span><span class="err">\</span><span class="s">w+'</span><span class="p">)</span>
<span class="p">[</span><span class="s">'Quotes'</span><span class="p">]</span>
</code></pre>
</div>
<p>为了寻找合适的css选择器,可以输入<code class="highlighter-rouge">view(response)</code>,在默认的浏览器上打开该页面,然后使用浏览器上的开发者工具进行查看.</p>

<h3 id="xpath的简单介绍">XPath的简单介绍</h3>
<p>除了css选择器,scrapy也支持xpath语句:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//title'</span><span class="p">)</span>
<span class="p">[</span><span class="o">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">'//title'</span><span class="n">data</span><span class="s">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span><span class="o">&gt;</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//title/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="s">'Quotes to Scrape'</span>
</code></pre>
</div>
<p>XPath语句十分强大,也是Scrapy选择器里使用的内部语句.实际上,CSS选择也是转变为XPath.可以在先前css选择的结果中看出来.<br />
虽然不像css那么流行,但XPath语句提供了更强大的功能,除了按元素构造进行导航,还可以解析元素的内容.使用XPath,可以这么选: <strong>选择包含’下一页’的链接</strong>.这种便利使得XPath十分适合用于爬取工作,即使已经学会了css选择器的用法也还是推荐学习下XPath的语法.</p>

<h3 id="提取论点与作者信息">提取论点与作者信息</h3>
<p>现在已经知道了如何选择与提取,接下来完善我们的spider.<br />
在’http://quotes.toscrape.com’上的每个页面的HTML元素大致如下:</p>
<div class="language-html highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">'quote'</span><span class="nt">&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">'text'</span><span class="nt">&gt;</span> "The world as we have created it is a process of our thinking.It cannot be changed without changing our thinking."<span class="nt">&lt;/span&gt;</span>
    <span class="nt">&lt;span&gt;</span>
        by<span class="nt">&lt;small</span> <span class="na">class=</span><span class="s">'author'</span><span class="nt">&gt;</span>Albert Einstein<span class="nt">&lt;/small&gt;</span>
        <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">'/author/Albert-Einstein'</span><span class="nt">&gt;</span>(about)<span class="nt">&lt;/a&gt;</span>
    <span class="nt">&lt;/span&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">'tag'</span><span class="nt">&gt;</span>
        Tag:
        <span class="nt">&lt;a</span> <span class="na">class=</span><span class="s">'tag'</span> <span class="na">href=</span><span class="s">'/tag/change/page/1'</span><span class="nt">&gt;</span>change<span class="nt">&lt;/a&gt;</span>
        <span class="nt">&lt;a</span> <span class="na">class=</span><span class="s">'tag'</span> <span class="na">href=</span><span class="s">'/tag/deep-thoughtes/page/1'</span><span class="nt">&gt;</span>deep-thoughtes<span class="nt">&lt;/a&gt;</span>
        <span class="nt">&lt;a</span> <span class="na">class=</span><span class="s">'tag'</span> <span class="na">href=</span><span class="s">'/tag/thinking/page/1'</span><span class="nt">&gt;</span>thinking<span class="nt">&lt;/a&gt;</span>
        <span class="nt">&lt;a</span> <span class="na">class=</span><span class="s">'tag'</span> <span class="na">href=</span><span class="s">'/tag/world/page/1'</span><span class="nt">&gt;</span>world<span class="nt">&lt;/a&gt;</span>
    <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre>
</div>
<p>跟原先一样,打开终端来分析如何提取: <code class="highlighter-rouge">scrapy shell 'http://quotes.toscrape.com'</code><br />
先提取’quote’元素:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">)</span>
</code></pre>
</div>
<p>每次选择器会返回一个对象,让我们进一步进行元素细分.所以我们先将提取到的整个’quote’元素保存到一个变量中,下面可以直接使用这个变量来提取:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">quote</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre>
</div>
<p>接下来提取’title’,’author’和’tag’:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">title</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="o">&gt;&gt;</span> <span class="n">title</span>
<span class="s">'"The world as we have created it is a process of our thinking.It cannot be changed without changing our thinking."'</span>
<span class="o">&gt;&gt;</span> <span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="o">&gt;&gt;</span> <span class="n">author</span>
<span class="s">'Albert Einstein'</span>
</code></pre>
</div>
<p>由于’tag’是有多个,我们可以使用<code class="highlighter-rouge">extract()</code>来提取全部:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">tag</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="o">&gt;&gt;</span> <span class="n">tag</span>
<span class="p">[</span><span class="s">'change'</span><span class="p">,</span> <span class="s">'deep-thoughts'</span><span class="p">,</span> <span class="s">'thinking'</span><span class="p">,</span> <span class="s">'world'</span><span class="p">]</span>
</code></pre>
</div>
<p>知道了如何提取所有信息后,可以将他们整合起来并放到一个python的字典中:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">):</span>
<span class="o">...</span>     <span class="n">text</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="o">...</span>     <span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="o">...</span>     <span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="o">...</span>     <span class="k">print</span><span class="p">(</span><span class="nb">dict</span><span class="o">=</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">author</span><span class="o">=</span><span class="n">author</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">))</span>
<span class="p">{</span><span class="s">'tags'</span><span class="p">:[</span><span class="s">'change'</span><span class="p">,</span> <span class="s">'deep-thoughts'</span><span class="p">,</span> <span class="s">'thinking'</span><span class="p">,</span> <span class="s">'world'</span><span class="p">],</span><span class="s">'author'</span><span class="p">:</span><span class="s">'Albert Einstein'</span><span class="p">,</span><span class="s">'text'</span><span class="p">:</span><span class="s">'"The world as we have created it is a process of our thinking.It cannot be changed without changing our thinking."'</span><span class="p">}</span>
<span class="p">{</span><span class="o">...</span><span class="p">}</span>
<span class="o">...</span>
</code></pre>
</div>

<h3 id="在spider中提取数据">在spider中提取数据</h3>
<p>回到我们的spider中,直到现在它都没有提取什么特别的数据,只是将整个HTML页面保存在本地.我们将上面的代码整合到spider中.<br />
典型的Scrapy的spider会生成许多包含有从页面中提取出来的数据的字典.我们可以在回调函数中使用<code class="highlighter-rouge">yield</code>关键字来达到这个目的:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'quotes'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
        <span class="s">'http://quotes.toscrape.com/page/2/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="p">}</span>
</code></pre>
</div>

<h3 id="储存爬取到的数据">储存爬取到的数据</h3>
<p>存储爬取的到的数据,最简单的方法是直接导出保存.可以在运行脚本时如下输入: <code class="highlighter-rouge">scrapy crawl quotes -o quotes.json</code><br />
这将会生成一个quotes.json的文件,其包含所有抓取到的数据,以json的格式存储.<br />
基于一些历史原因,Scrapy会在提供的文件上添加内容而不是重写它的内容.如果你使用这条命令两次而没有移除第一次生成的json文件,这将导致第二次的json文件出错.<br />
为此,可以选择使用另一种格式,像是<a href="http://jsonlines.org">JSON Lines</a>:<br />
<code class="highlighter-rouge">scrapy crawl quotes -o quotes.jl</code><br />
JSON Lines格式十分好用,他是一种数据流的形式,你可以很方便的在原有数据后面添加新的数据.即使运行同一个命令两次,也不会遇到像JSON那样的问题.同时,因为每一个记录都为独立的一行,你可以读写一个大文件而不用将它整个放到内存里,有很多像是<a href="https://stedolan.github.io/jq">JQ</a>这样的工具能在命令行里使用.<br />
在一些小型的项目(就像我们这个)里,这样就够了.但,如果你想要适应更加复杂的情况,可以写一个<code class="highlighter-rouge">Item Pipeline</code>.如果只是想要存储一些爬取的数据,倒可不必关心这些.</p>

<h3 id="爬取接下来的链接">爬取接下来的链接</h3>
<p>不止是爬取两页,我们一般更想要爬取一个网站上的所有页面.<br />
我们已经知道如何提取数据了,现在来看看如何设置接下来要爬取的方法.<br />
要爬取下一页内容,首先就要找到’下一页’的链接.还是看我们这个例子,可以看到在页面中有这样一段标明了下一页的链接:</p>
<div class="language-html highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;ul</span> <span class="na">class=</span><span class="s">'pager'</span><span class="nt">&gt;</span>
    <span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">'next'</span><span class="nt">&gt;</span>
        <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">'/page/2/'</span><span class="nt">&gt;</span>Next <span class="nt">&lt;span</span> <span class="na">aria-hidden=</span><span class="s">'true'</span><span class="nt">&gt;</span><span class="ni">&amp;rarr;</span><span class="nt">&lt;/span&gt;&lt;/a&gt;</span>
    <span class="nt">&lt;/li&gt;</span>
<span class="nt">&lt;/ul&gt;</span>
</code></pre>
</div>
<p>在终端中进行如下尝试:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="s">'&lt;a href="/page/2/"&gt;Next &lt;span aria-hidden="true"&gt;-&gt;&lt;/span&gt;&lt;/a&gt;'</span>
</code></pre>
</div>
<p>这将得到整个a元素,但我们只想要他的<code class="highlighter-rouge">href</code>属性.为此,Scrapy提供一个CSS的方法扩展来让用户选择属性的内容,就像这样:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
<span class="s">'/page/2/'</span>
</code></pre>
</div>
<p>现在让我们的Spider来自动获取下一页的链接并进行爬取:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'quotes'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre>
</div>
<p>现在,在提取完页面的数据后,<code class="highlighter-rouge">parse()</code>方法会寻找下一页的链接,通过<code class="highlighter-rouge">urljoin()</code>方法构造绝对路径url,然后进行新的页面的请求,将自己注册为回调函数来处理下一页的数据提取以此来顺序抓取所有页面.<br />
这就是Scrapy中顺序抓取的大致过程:当在回调函数中返回一个请求,Scrapy将会安排这个请求的发送与回调函数的注册.<br />
通过这种方法,就可以自定义规则来构造复杂的爬虫代码,并解析不同类型的数据.<br />
这个例子中,会产生多重循环来抓取所有页面直到结束–对于抓取博客,论坛或者其他带分页的站点就十分方便.</p>

<h3 id="生成请求的简化">生成请求的简化</h3>
<p>我们可以使用<code class="highlighter-rouge">response.follow</code>来简化生成请求的操作:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'quotes'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
        
        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre>
</div>
<p>跟<code class="highlighter-rouge">scrapy.Request</code>不同,<code class="highlighter-rouge">response.follow</code>方法支持直接传进相对路径url–不需要调用<code class="highlighter-rouge">urljoin</code>方法.需要注意的是,<code class="highlighter-rouge">response.follow</code>方法只会返回一个请求的实例,所以还要来发出这个请求.<br />
你也可以传入一个选择器给<code class="highlighter-rouge">response.follow</code>来代替字符串;该选择器将会提取必要的属性:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a::attr(href)'</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre>
</div>
<blockquote>
  <p>针对&lt;a&gt;元素,<code class="highlighter-rouge">response.follow</code>会自动寻找它的<code class="highlighter-rouge">href</code>属性.所以该代码可以简化为:</p>
  <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a'</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre>
  </div>
  <p><strong>注意:</strong> <code class="highlighter-rouge">response.follow(response.css('li.next a'))</code>这样写是不对的,因为<code class="highlighter-rouge">response.css</code>返回的是一个列表对象而不是单独一个选择器.使用for循环或者像是<code class="highlighter-rouge">response.follow(response.css('li.next a')[0])</code>才是对的.</p>
</blockquote>

<h3 id="更多例子">更多例子</h3>
<p>接下来是另一个spider,它指明不同的回调函数与下一页链接,对作者信息进行抓取:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">AuthorSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'author'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://quotes.toscrape.com/'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c"># 爬取作者页面</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'.author + a::attr(href)'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_author</span><span class="p">)</span>

        <span class="c"># 爬取下一页</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a::attr(href)'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">parse_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">extract_with_css</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="k">yield</span> <span class="p">{</span>
            <span class="s">'name'</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s">'h3.author-title::text'</span><span class="p">),</span>
            <span class="s">'birthdate'</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s">'.author-born-date::text'</span><span class="p">),</span>
            <span class="s">'bio'</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s">'.author-description::text'</span><span class="p">),</span>
        <span class="p">}</span>
</code></pre>
</div>
<p>这个spider将会从主页面开始,每次遇到指向作者页面的链接时就调用<code class="highlighter-rouge">parse_author</code>方法进行处理,遇到下一页的链接时则调用<code class="highlighter-rouge">parse</code>方法进行处理.<br />
这里我们将回调函数传入<code class="highlighter-rouge">response.follow</code>来让代码更简洁,使用<code class="highlighter-rouge">scrapy.Request</code>也是可以的.<br />
回调函数<code class="highlighter-rouge">parse_author</code>内部定义了一个辅助函数用来提取与清理从css选择器得到的数据,并生成一个python的字典来保存作者的信息.<br />
还有一件很有趣的事情就是,即使许多页面是出自同一个作者,我们也不用担心会多次访问到相同的作者页面.Scrapy会自动过滤掉已经访问过了的重复的页面,避免这种程序上的错误导致的多次访问服务器.这项设置可以通过更改<code class="highlighter-rouge">DUPEFILTER_CLASS</code>来配置.</p>

<h3 id="使用一些spider的参数">使用一些spider的参数</h3>
<p>在运行爬虫时,可以加入<code class="highlighter-rouge">-a</code>参数:<br />
<code class="highlighter-rouge">scrapy crawl quotes -o quotes-humor.json -a tag=humor</code><br />
这些参数会传递到spider的初始化方法中作为spider的默认属性.这这个例子中,通过tag传入的值会通过<code class="highlighter-rouge">self.tag</code>发生作用,可以使用这个方法来指定特定的tag下的quote:</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'quotes'</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">'http://quotes.toscrape.com/'</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'tag'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">url</span> <span class="o">+</span> <span class="s">'tag/'</span> <span class="o">+</span> <span class="n">tag</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
        
        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre>
</div>
<p>若将<code class="highlighter-rouge">tag=humor</code>参数传入spider,它将只抓取带有’humor’标签的页面,比如:’http://quotes.toscrape.com/tag/humor’.</p>

<hr />
<h2 id="结尾">结尾</h2>
<p>关于Scrapy的官方例子学习就到这里,本篇只涉及了scrapy的基础使用,关于一些高级方法的使用学习有空再更吧.</p>

    
  </div>

  
  
</div>

    </main>

    

    <div id="actGotop" class="fa fa-angle-up" style="display: none;"></div>
    <script type="text/javascript">
      // 回到顶部功能
      $('.container').scroll(function(){
        if($('.container').scrollTop() >= 1000){
          $('#actGotop').fadeIn(300);
        }else{
          $('#actGotop').fadeOut(300);
        }
      });
      $('#actGotop').click(function(){
        $('.container').animate({scrollTop: '0px'}, 800);
        console.log('click')
      });
    </script>
  </body>
</html>
